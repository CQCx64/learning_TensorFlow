{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-adea327c6e69>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Tool\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From E:\\Tool\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Tool\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Tool\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From E:\\Tool\\anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From E:\\Tool\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Iter 0,Testing Accuracy 0.8329\n",
      "Iter 1,Testing Accuracy 0.8702\n",
      "Iter 2,Testing Accuracy 0.8808\n",
      "Iter 3,Testing Accuracy 0.8877\n",
      "Iter 4,Testing Accuracy 0.893\n",
      "Iter 5,Testing Accuracy 0.897\n",
      "Iter 6,Testing Accuracy 0.9002\n",
      "Iter 7,Testing Accuracy 0.9019\n",
      "Iter 8,Testing Accuracy 0.9038\n",
      "Iter 9,Testing Accuracy 0.9051\n",
      "Iter 10,Testing Accuracy 0.9056\n",
      "Iter 11,Testing Accuracy 0.9071\n",
      "Iter 12,Testing Accuracy 0.9076\n",
      "Iter 13,Testing Accuracy 0.9094\n",
      "Iter 14,Testing Accuracy 0.9108\n",
      "Iter 15,Testing Accuracy 0.9109\n",
      "Iter 16,Testing Accuracy 0.9118\n",
      "Iter 17,Testing Accuracy 0.9126\n",
      "Iter 18,Testing Accuracy 0.9128\n",
      "Iter 19,Testing Accuracy 0.913\n",
      "Iter 20,Testing Accuracy 0.9138\n"
     ]
    }
   ],
   "source": [
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小\n",
    "batch_size = 100\n",
    "#计算一共有多少个批次\n",
    "#数据集总数量整除每个批次大小\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "#行和批次有关，列784，代表28*28个像素点\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "#行和批次有关，列10，代表10种分类\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个简单的神经网络\n",
    "W = tf.Variable(tf.zeros([784,10]))\n",
    "b = tf.Variable(tf.zeros([10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(x,W) + b)\n",
    "\n",
    "#二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#使用梯度下降法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#tf.argmax(input, axis=None)表示求批次数据axis上值最大的索引\n",
    "#argmax(y,1)沿着y每行找列上最大值所在的列索引\n",
    "#.equal(A,B)比较AB值是否一样，返回bool型列表\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#求准确率,cast()转换类型,再求平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(21):\n",
    "        for batch in range(n_batch):\n",
    "            #每一个batch_size的图片保存在batch_xs，标签保存在batch_ys\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        \n",
    "        print('Iter ' + str(epoch) + ',Testing Accuracy ' + str(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "Iter 0,Testing Accuracy 0.0974\n",
      "Iter 20,Testing Accuracy 0.8478\n",
      "Iter 40,Testing Accuracy 0.8596\n",
      "Iter 60,Testing Accuracy 0.8652\n",
      "Iter 80,Testing Accuracy 0.9651\n",
      "Iter 100,Testing Accuracy 0.9658\n"
     ]
    }
   ],
   "source": [
    "#v2.0 提高准确率至95%+\n",
    "\n",
    "#载入数据集\n",
    "mnist = input_data.read_data_sets(\"MNIST_data\",one_hot=True)\n",
    "\n",
    "#每个批次的大小，减小批次提高准确率\n",
    "batch_size = 120\n",
    "#计算一共有多少个批次\n",
    "#数据集总数量整除每个批次大小\n",
    "n_batch = mnist.train.num_examples // batch_size\n",
    "\n",
    "#定义两个placeholder\n",
    "#行和批次有关，列784，代表28*28个像素点\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "#行和批次有关，列10，代表10种分类\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "#创建一个带有一层hidden layer的神经网络\n",
    "#使用正态分布随机W，提高准确率\n",
    "W_L1 = tf.Variable(tf.zeros([784,100]))\n",
    "b_L1 = tf.Variable(tf.random_normal([1,100]))\n",
    "#输入使用relu激活函数\n",
    "L1 = tf.nn.relu(tf.matmul(x,W_L1) + b_L1)\n",
    "#隐藏层，使用100个神经单元\n",
    "W_L2 = tf.Variable(tf.random_normal([100,10]))\n",
    "b_L2 = tf.Variable(tf.random_normal([1,10]))\n",
    "prediction = tf.nn.softmax(tf.matmul(L1,W_L2) + b_L2)\n",
    "\n",
    "#二次代价函数\n",
    "loss = tf.reduce_mean(tf.square(y-prediction))\n",
    "#使用梯度下降法\n",
    "#降低学习率\n",
    "train_step = tf.train.GradientDescentOptimizer(0.3).minimize(loss)\n",
    "\n",
    "#初始化变量\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#tf.argmax(input, axis=None)表示求批次数据axis上值最大的索引\n",
    "#argmax(y,1)沿着y每行找列上最大值所在的列索引\n",
    "#.equal(A,B)比较AB值是否一样，返回bool型列表\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(prediction,1))\n",
    "#求准确率,cast()转换类型,再求平均值\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #增加迭代次数\n",
    "    for epoch in range(101):\n",
    "        for batch in range(n_batch):\n",
    "            #每一个batch_size的图片保存在batch_xs，标签保存在batch_ys\n",
    "            batch_xs,batch_ys = mnist.train.next_batch(batch_size)\n",
    "            sess.run(train_step,feed_dict={x:batch_xs,y:batch_ys})\n",
    "        acc = sess.run(accuracy,feed_dict={x:mnist.test.images,y:mnist.test.labels})\n",
    "        if epoch % 20 == 0:\n",
    "            print('Iter ' + str(epoch) + ',Testing Accuracy ' + str(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
